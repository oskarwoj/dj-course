# Azor ChatDog (TypeScript)

Interactive AI chat assistant in TypeScript - migrated from Python. Azor is your friendly dog assistant with great capabilities!

## Features

- ğŸ¶ Interactive chat with AI assistant (Azor)
- ğŸ”„ Session management (create, switch, load, save)
- ğŸ’¾ Persistent chat history with JSON storage
- ğŸ“ Write-Ahead Log (WAL) for transaction tracking
- ğŸ“Š Token usage tracking and display
- ğŸ“„ Export sessions to PDF
- ğŸ¨ Colorful terminal output with chalk
- ğŸ”Œ Support for multiple LLM backends:
  - Google Gemini
  - Local LLaMA (via node-llama-cpp)

## Prerequisites

- Node.js 20+
- npm or yarn
- Google Gemini API key (for Gemini engine)
- LLaMA model file in GGUF format (for LLaMA engine)

## Installation

1. Clone the repository
2. Install dependencies:

```bash
npm install
```

3. Create a `.env` file based on `.env.example`:

```bash
cp .env.example .env
```

4. Configure your `.env` file with your API keys and settings

## Configuration

### Gemini Configuration

```env
ENGINE=GEMINI
GEMINI_API_KEY=your_api_key_here
MODEL_NAME=gemini-2.0-flash-exp
```

### LLaMA Configuration

```env
ENGINE=LLAMA_CPP
LLAMA_MODEL_NAME=llama-3.1-8b-instruct
LLAMA_MODEL_PATH=/path/to/model.gguf
LLAMA_GPU_LAYERS=1
LLAMA_CONTEXT_SIZE=2048
```

## Usage

### Development Mode

```bash
npm run dev
```

### Build and Run

```bash
npm run build
npm start
```

### Run with Specific Session

```bash
npm run dev -- --session-id=<SESSION_ID>
```

## Available Commands

### Chat Commands

- `/help` - Display available commands
- `/exit` or `/quit` - Exit the chat
- `/switch <SESSION_ID>` - Switch to a different session

### Session Management

- `/session list` - List all available sessions
- `/session display` - Display full conversation history
- `/session pop` - Remove last exchange (user + assistant)
- `/session clear` - Clear current session history
- `/session new` - Start a new session
- `/session remove` - Remove current session and start fresh

### Export

- `/pdf` - Export current session to PDF

## Project Structure

```
azor-chatdog-ts/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts                 # Entry point
â”‚   â”œâ”€â”€ chat.ts                  # Main loop
â”‚   â”œâ”€â”€ commandHandler.ts        # Command routing
â”‚   â”œâ”€â”€ types.ts                 # TypeScript type definitions
â”‚   â”œâ”€â”€ assistant/
â”‚   â”‚   â”œâ”€â”€ assistant.ts
â”‚   â”‚   â””â”€â”€ azor.ts
â”‚   â”œâ”€â”€ session/
â”‚   â”‚   â”œâ”€â”€ index.ts            # Session manager singleton
â”‚   â”‚   â”œâ”€â”€ chatSession.ts
â”‚   â”‚   â””â”€â”€ sessionManager.ts
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ geminiClient.ts
â”‚   â”‚   â”œâ”€â”€ geminiValidation.ts
â”‚   â”‚   â”œâ”€â”€ llamaClient.ts
â”‚   â”‚   â””â”€â”€ llamaValidation.ts
â”‚   â”œâ”€â”€ cli/
â”‚   â”‚   â”œâ”€â”€ args.ts
â”‚   â”‚   â”œâ”€â”€ console.ts
â”‚   â”‚   â””â”€â”€ prompt.ts
â”‚   â”œâ”€â”€ commands/
â”‚   â”‚   â”œâ”€â”€ welcome.ts
â”‚   â”‚   â”œâ”€â”€ sessionList.ts
â”‚   â”‚   â”œâ”€â”€ sessionDisplay.ts
â”‚   â”‚   â”œâ”€â”€ sessionSummary.ts
â”‚   â”‚   â”œâ”€â”€ sessionToPdf.ts
â”‚   â”‚   â””â”€â”€ sessionRemove.ts
â”‚   â””â”€â”€ files/
â”‚       â”œâ”€â”€ config.ts
â”‚       â”œâ”€â”€ sessionFiles.ts
â”‚       â”œâ”€â”€ wal.ts
â”‚       â””â”€â”€ pdf/
â”‚           â”œâ”€â”€ pdf.ts
â”‚           â””â”€â”€ fonts/           # Lato fonts
â”œâ”€â”€ dist/                        # Compiled output
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## Session Storage

Sessions are stored in `~/.azor/` directory:
- Session files: `~/.azor/<session-id>-log.json`
- WAL file: `~/.azor/azor-wal.json`
- PDF exports: `~/.azor/output/`

## Development

### Type Checking

```bash
npx tsc --noEmit
```

### Running Tests

```bash
npm test
```

## Migration from Python

This is a TypeScript port of the original Python `azor-chatdog` project. Key changes:

- **Type Safety**: Full TypeScript support with strict typing
- **Module System**: ESM modules with proper `.js` extensions
- **Async/Await**: Consistent async patterns throughout
- **Libraries**:
  - `colorama` â†’ `chalk`
  - `prompt_toolkit` â†’ `@inquirer/prompts`
  - `argparse` â†’ `commander`
  - `pydantic` â†’ `zod`
  - `fpdf` â†’ `pdfkit`

## Troubleshooting

### LLaMA Model Issues

If you encounter issues loading LLaMA models:
- Ensure your model is in GGUF format
- Check that the path in `.env` is correct
- Adjust `LLAMA_GPU_LAYERS` based on your hardware

### Gemini API Issues

- Verify your API key is valid
- Check internet connectivity
- Ensure the model name is correct

## License

This project is licensed under the MIT License.

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.
